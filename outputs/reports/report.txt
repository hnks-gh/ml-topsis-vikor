====================================================================================================

            MULTI-CRITERIA DECISION MAKING ANALYSIS WITH MACHINE LEARNING
                    A Comprehensive Evaluation of Regional Sustainability

====================================================================================================

Report Generated: 2026-02-11 01:20:04
Analysis Period: 2011 - 2024
Computational Time: 721.03 seconds

----------------------------------------------------------------------------------------------------
EXECUTIVE SUMMARY
----------------------------------------------------------------------------------------------------

This report presents a comprehensive multi-criteria decision making (MCDM) analysis
of 64 regional entities across 14 time periods (2011-2024),
evaluating performance based on 29 sustainability criteria.

KEY FINDINGS:

  1. TOP PERFORMER: P14 consistently ranks as the leading entity across
     all MCDM methods, demonstrating superior performance in sustainability metrics.

  2. METHOD AGREEMENT: Kendall's W coefficient of 0.9681 indicates excellent
     agreement among the 11 MCDM methods employed (6 traditional + 5 fuzzy),
     providing high confidence in the robustness of our rankings.

  3. PREDICTIVE ACCURACY: Machine learning models achieve R² = 0.8456, demonstrating
     strong capability to explain and forecast sustainability performance patterns.

  4. FORECAST: P14 is predicted to maintain top performance in 2025,
     with an expected TOPSIS score of 0.8585.


====================================================================================================
1. INTRODUCTION AND METHODOLOGY
====================================================================================================

1.1 Research Context
--------------------------------------------------

Multi-criteria decision making (MCDM) provides a systematic framework for evaluating
alternatives against multiple, often conflicting criteria. This analysis employs an
integrated approach combining traditional MCDM methods, fuzzy extensions for handling
uncertainty, and machine learning for pattern recognition and forecasting.

1.2 Dataset Description
--------------------------------------------------

  • Entities Analyzed: 64 regional units (provinces/regions)
  • Temporal Coverage: 14 years (2011-2024)
  • Evaluation Criteria: 29 sustainability components
  • Total Observations: 896 entity-year records

1.3 Methodological Framework
--------------------------------------------------

This analysis integrates multiple analytical approaches:

  WEIGHTING METHODS:
    • Entropy Method: Derives weights from information content and variability
    • CRITIC Method: Incorporates both contrast intensity and inter-criteria correlation
    • PCA Method: Extracts weights from principal component loadings and explained variance
    • Ensemble Weights: Integrated hybrid of Entropy, CRITIC and PCA weights

  MCDM METHODS (11 methods total):
    Traditional Methods:
      1. TOPSIS - Technique for Order Preference by Similarity to Ideal Solution
      2. Dynamic TOPSIS - Panel data extension with temporal dynamics
      3. VIKOR - Multi-criteria optimization and compromise solution
      4. PROMETHEE - Preference ranking with pairwise comparisons
      5. COPRAS - Complex proportional assessment of alternatives
      6. EDAS - Evaluation based on distance from average solution
    Fuzzy Extensions (handling temporal uncertainty):
      7. Fuzzy TOPSIS
      8. Fuzzy VIKOR
      9. Fuzzy PROMETHEE
      10. Fuzzy COPRAS
      11. Fuzzy EDAS

  MACHINE LEARNING:
    • Random Forest with time-series cross-validation for feature importance
    • Unified Ensemble Forecasting (Gradient Boosting + Random Forest + Bayesian Ridge)
    • Future year prediction using all historical data

  ENSEMBLE INTEGRATION:
    • Stacking ensemble with meta-learner optimization
    • Borda count rank aggregation for consensus ranking


====================================================================================================
2. CRITERIA WEIGHTING ANALYSIS
====================================================================================================

Objective weighting methods were employed to determine the relative importance of each
criterion based on data characteristics, eliminating subjective bias in weight assignment.

2.1 ENTROPY Weights
--------------------------------------------------
The entropy method measures weight based on the amount of information conveyed by
each criterion. Criteria with greater variation carry more information and receive
higher weights.

  Statistical Summary:
    Minimum Weight: 0.020217
    Maximum Weight: 0.046438
    Mean Weight: 0.034483
    Standard Deviation: 0.005808
    Weight Concentration (Max/Min ratio): 2.30x

  Top 5 Most Important Criteria:
    1. C14: 0.046438 (4.6% of total)
    2. C16: 0.041592 (4.2% of total)
    3. C23: 0.041585 (4.2% of total)
    4. C28: 0.040627 (4.1% of total)
    5. C20: 0.040577 (4.1% of total)

2.2 CRITIC Weights
--------------------------------------------------
CRITIC (Criteria Importance Through Intercriteria Correlation) accounts for both
the contrast intensity (standard deviation) and conflicting relationships between
criteria to determine weights.

  Statistical Summary:
    Minimum Weight: 0.030140
    Maximum Weight: 0.037876
    Mean Weight: 0.034483
    Standard Deviation: 0.002072
    Weight Concentration (Max/Min ratio): 1.26x

  Top 5 Most Important Criteria:
    1. C16: 0.037876 (3.8% of total)
    2. C17: 0.037312 (3.7% of total)
    3. C14: 0.037125 (3.7% of total)
    4. C28: 0.036916 (3.7% of total)
    5. C20: 0.036882 (3.7% of total)

2.3 PCA Weights
--------------------------------------------------
PCA (Principal Component Analysis) derives weights from the variance structure of
the data. Weights reflect each criterion's contribution to the principal components,
weighted by explained variance ratios.

  Statistical Summary:
    Minimum Weight: 0.028571
    Maximum Weight: 0.039545
    Mean Weight: 0.034483
    Standard Deviation: 0.003270
    Weight Concentration (Max/Min ratio): 1.38x

  Top 5 Most Important Criteria:
    1. C01: 0.039545 (4.0% of total)
    2. C22: 0.038259 (3.8% of total)
    3. C28: 0.038237 (3.8% of total)
    4. C23: 0.038213 (3.8% of total)
    5. C26: 0.038061 (3.8% of total)

2.4 ENSEMBLE Weights
--------------------------------------------------
Ensemble weights combine Entropy, CRITIC and PCA methods through the integrated
hybrid strategy to leverage the strengths of each individual approach.

  Statistical Summary:
    Minimum Weight: 0.030941
    Maximum Weight: 0.036993
    Mean Weight: 0.034483
    Standard Deviation: 0.001603
    Weight Concentration (Max/Min ratio): 1.20x

  Top 5 Most Important Criteria:
    1. C28: 0.036993 (3.7% of total)
    2. C24: 0.036634 (3.7% of total)
    3. C23: 0.036600 (3.7% of total)
    4. C14: 0.036589 (3.7% of total)
    5. C29: 0.036486 (3.6% of total)

INTERPRETATION:
The ensemble weighting identifies C28, C24, C23 as the most critical criteria
for sustainability assessment. These criteria exhibit both high variability and
significant discriminatory power, making them essential factors in distinguishing
high-performing entities from lower-performing ones.


====================================================================================================
3. MULTI-CRITERIA DECISION MAKING RESULTS
====================================================================================================

3.1 TOPSIS (Technique for Order Preference by Similarity to Ideal Solution)
--------------------------------------------------

TOPSIS identifies the alternative that is simultaneously closest to the positive ideal
solution and farthest from the negative ideal solution. Scores range from 0 to 1,
where higher values indicate better overall performance.

  Performance Distribution:
    Best Score: 0.829630
    Worst Score: 0.210553
    Mean Score: 0.491361
    Median Score: 0.462707
    Standard Deviation: 0.185321
    Coefficient of Variation: 37.7%

  Top 10 Performing Entities:
  ----------------------------------------------------------------------
  Rank   Entity          TOPSIS Score    Performance Level
  ----------------------------------------------------------------------
  1      P14             0.829630        Excellent
  2      P13             0.802754        Excellent
  3      P06             0.801584        Excellent
  4      P04             0.785685        Excellent
  5      P03             0.783176        Excellent
  6      P01             0.779596        Excellent
  7      P05             0.779245        Excellent
  8      P08             0.778742        Excellent
  9      P10             0.773246        Excellent
  10     P07             0.771233        Excellent
  ----------------------------------------------------------------------

3.2 VIKOR (Multi-Criteria Optimization and Compromise Solution)
--------------------------------------------------

VIKOR focuses on ranking and selecting alternatives with conflicting criteria,
emphasizing compromise solutions. Lower Q values indicate better performance.

  VIKOR Metrics Summary:
    Q (Compromise) Range: [0.000000, 1.000000]
    S (Group Utility) Range: [0.136144, 0.842786]
    R (Individual Regret) Range: [0.010575, 0.036993]

  Top 10 VIKOR Rankings (lowest Q = best):
  --------------------------------------------------------------------------------
  Rank   Entity       Q Value      S Value      R Value      Status
  --------------------------------------------------------------------------------
  1      P14          0.000000     0.136144     0.010575     Best Compromise
  2      P06          0.081805     0.153400     0.014252     -
  3      P01          0.109542     0.192908     0.014240     -
  4      P12          0.110990     0.224134     0.013149     -
  5      P05          0.118341     0.191251     0.014767     -
  6      P08          0.119177     0.196166     0.014628     -
  7      P04          0.121005     0.185257     0.015132     -
  8      P13          0.124249     0.150210     0.016614     -
  9      P07          0.140821     0.199772     0.015636     -
  10     P03          0.153010     0.174300     0.017233     -
  --------------------------------------------------------------------------------

3.3 Fuzzy TOPSIS
--------------------------------------------------

Fuzzy TOPSIS extends classical TOPSIS by representing criteria values as triangular
fuzzy numbers, capturing temporal variance and measurement uncertainty. This approach
provides more robust rankings under data imprecision.

  Fuzzy Score Range: [0.164614, 0.855213]
  Mean Fuzzy Score: 0.489593

3.4 Dynamic TOPSIS (Panel-Aware Extension)
--------------------------------------------------

Dynamic TOPSIS incorporates temporal dynamics by considering:
  • Trajectory analysis: Direction and rate of performance change over time
  • Stability weighting: Consistency of performance across periods
  • Temporal discounting: Greater emphasis on recent performance

  Dynamic Score Range: [0.204731, 0.838131]
  Mean Dynamic Score: 0.510693

3.5 PROMETHEE (Preference Ranking Organization Method)
--------------------------------------------------

PROMETHEE employs pairwise comparison with preference functions to establish
dominance relationships. The net flow (Φ_net) represents overall preference,
where higher values indicate better performance.

  PROMETHEE Flow Metrics:
    Φ_net (Net Flow) Range: [-0.677726, 0.755595]
    Φ+ (Positive Flow) Range: [0.043254, 0.782975]
    Φ- (Negative Flow) Range: [0.027380, 0.727690]

  Top 5 PROMETHEE II Rankings:
    1. P14: Φ_net = 0.755595
    2. P13: Φ_net = 0.721813
    3. P06: Φ_net = 0.715942
    4. P03: Φ_net = 0.688792
    5. P04: Φ_net = 0.683633

3.6 COPRAS (Complex Proportional Assessment)
--------------------------------------------------

COPRAS evaluates alternatives by separately assessing beneficial and non-beneficial
criteria, with utility degree as the final performance measure (0-100%).

  COPRAS Performance Metrics:
    Utility Degree Range: 49.18% - 100.00%
    Mean Utility: 73.12%
    Q Index Range: [0.010509, 0.021369]

  Top 5 COPRAS Rankings:
    1. P14: Utility = 100.00%
    2. P13: Utility = 99.25%
    3. P06: Utility = 98.88%
    4. P03: Utility = 97.19%
    5. P10: Utility = 96.98%

3.7 EDAS (Evaluation based on Distance from Average Solution)
--------------------------------------------------

EDAS assesses alternatives based on distance from average solution (AV).
The appraisal score (AS) combines positive and negative distances, where
higher AS values indicate superior performance. Range: 0 to 1.

  EDAS Metrics:
    Appraisal Score (AS) Range: [0.000000, 1.000000]
    Mean AS: 0.483326
    Positive Distance (SP) Mean: 0.099918
    Negative Distance (SN) Mean: 0.099918

  Top 5 EDAS Rankings:
    1. P14: AS = 1.000000
    2. P13: AS = 0.986111
    3. P06: AS = 0.979084
    4. P03: AS = 0.947553
    5. P10: AS = 0.943658

3.8 Fuzzy MCDM Extensions
--------------------------------------------------

All five traditional methods (TOPSIS, VIKOR, PROMETHEE, COPRAS, EDAS) have
fuzzy counterparts that handle temporal uncertainty using triangular fuzzy
numbers derived from panel data variance.

  Fuzzy Method Performance Summary:
    Fuzzy VIKOR - Best Q: 0.032552
    Fuzzy PROMETHEE - Best Φ_net: 0.721783
    Fuzzy COPRAS - Best Utility: 100.00%
    Fuzzy EDAS - Best AS: 1.000000

3.9 Cross-Method Validation and Agreement
--------------------------------------------------

To validate ranking robustness, we compare results across all MCDM methods:

  TOPSIS vs VIKOR Spearman Correlation: 0.9456
  Interpretation: Excellent agreement between classical MCDM methods


====================================================================================================
4. MACHINE LEARNING ANALYSIS
====================================================================================================

4.1 Random Forest Feature Importance Analysis
--------------------------------------------------

A Random Forest regressor with time-series cross-validation was trained to predict
TOPSIS scores from criteria values. This analysis identifies which criteria most
strongly influence overall sustainability rankings.

  Model Performance Metrics:
    Test R-squared: 0.845585
    Test MAE: 0.062186
    Test RMSE: 0.072823
    Rank Correlation (Spearman): 0.971016

  Cross-Validation Results (Time-Series Split):
    R2: 0.885696 ± 0.039761
    MSE: 0.003926 ± 0.001366
    MAE: 0.051667 ± 0.011655
    RANK_CORR: 0.971589 ± 0.004892

  INTERPRETATION:
  The model demonstrates strong predictive capability with high explanatory power.

  Feature Importance Rankings:
  ------------------------------------------------------------
  Rank   Criterion       Importance   Cumulative %
  ------------------------------------------------------------
  1      C21             0.175609     17.6%
  2      C23             0.112723     28.8%
  3      C26             0.098594     38.7%
  4      C29             0.088434     47.5%
  5      C22             0.080408     55.6%
  6      C24             0.070960     62.7%
  7      C25             0.069898     69.7%
  8      C27             0.064144     76.1%
  9      C28             0.061214     82.2%
  10     C17             0.029263     85.1%
  11     C15             0.024981     87.6%
  12     C05             0.015379     89.2%
  13     C20             0.014305     90.6%
  14     C16             0.012363     91.8%
  15     C08             0.011144     92.9%
  ------------------------------------------------------------

  KEY INSIGHT:
  The top 3 criteria (C21, C23, C26) account for
  38.7% of the total feature importance, indicating these are the
  primary drivers of sustainability performance differentiation.


====================================================================================================
5. ENSEMBLE INTEGRATION AND FINAL RANKINGS
====================================================================================================

5.1 Stacking Ensemble Meta-Learner
--------------------------------------------------

A stacking ensemble combines predictions from all base MCDM methods using a
regularized meta-learner to optimize the final score predictions.

  Meta-Model Performance (R²): 0.019627

  Base Model Contribution Weights:
  --------------------------------------------------
    PROMETHEE           : 0.1722 ██████
    Fuzzy_PROMETHEE     : 0.1649 ██████
    Fuzzy_EDAS          : 0.1157 ████
    EDAS                : 0.1157 ████
    Fuzzy_VIKOR         : 0.1052 ████
    VIKOR_Q             : 0.1024 ████
    Fuzzy_TOPSIS        : 0.0825 ███
    TOPSIS              : 0.0770 ███
    Dynamic_TOPSIS      : 0.0617 ██
    Fuzzy_COPRAS        : 0.0013 
    COPRAS              : 0.0013 
  --------------------------------------------------

5.2 Rank Aggregation (Borda Count)
--------------------------------------------------

Borda count aggregation combines rankings from all MCDM methods by assigning
points based on rank position. This produces a consensus ranking that reflects
agreement across multiple methodological perspectives.

  Kendall's W (Inter-Method Agreement): 0.968080
  Interpretation: excellent agreement - rankings are highly consistent across methods

  FINAL CONSENSUS RANKINGS:
  ======================================================================
  Rank   Entity          Borda Score     Percentile
  ======================================================================
  1      P14             62.4545         ★★★ Top 10%
  2      P13             61.1818         ★★★ Top 10%
  3      P06             61.1818         ★★★ Top 10%
  4      P03             58.8182         ★★★ Top 10%
  5      P04             58.3636         ★★★ Top 10%
  6      P01             58.0000         ★★★ Top 10%
  7      P05             56.3636         ★★★ Top 10%
  8      P10             56.0909         ★★ Top 25%
  9      P08             55.6364         ★★ Top 25%
  10     P07             54.7273         ★★ Top 25%
  11     P12             53.3636         ★★ Top 25%
  12     P15             52.9091         ★★ Top 25%
  13     P09             50.3636         ★★ Top 25%
  14     P02             50.2727         ★★ Top 25%
  15     P11             49.6364         ★★ Top 25%
  16     P16             48.6364         ★★ Top 25%
  17     P27             46.6364         ★ Top 50%
  18     P20             44.9091         ★ Top 50%
  19     P21             43.9091         ★ Top 50%
  20     P26             43.0000         ★ Top 50%
  21     P25             41.9091         ★ Top 50%
  22     P40             41.3636         ★ Top 50%
  23     P38             39.6364         ★ Top 50%
  24     P17             38.8182         ★ Top 50%
  25     P36             38.5455         ★ Top 50%
  26     P37             37.0909         ★ Top 50%
  27     P29             35.8182         ★ Top 50%
  28     P41             33.5455         ★ Top 50%
  29     P48             33.0909         ★ Top 50%
  30     P46             32.2727         ★ Top 50%
  31     P28             32.1818         ★ Top 50%
  32     P24             31.7273         ★ Top 50%
  33     P44             31.4545         
  34     P18             30.8182         
  35     P23             29.0909         
  36     P43             28.0909         
  37     P31             28.0909         
  38     P47             26.2727         
  39     P19             25.5455         
  40     P22             24.6364         
  41     P34             24.1818         
  42     P35             23.7273         
  43     P39             22.1818         
  44     P45             21.9091         
  45     P32             20.0000         
  46     P30             19.0909         
  47     P33             19.0909         
  48     P42             17.7273         
  49     P62             14.0909         
  50     P51             13.8182         
  51     P58             13.0909         
  52     P63             11.4545         
  53     P55             11.1818         
  54     P59             11.0909         
  55     P50             8.6364          
  56     P56             8.1818          
  57     P60             7.9091          
  58     P53             6.0000          
  59     P64             4.5455          
  60     P54             3.7273          
  61     P57             3.7273          
  62     P49             2.4545          
  63     P52             1.6364          
  64     P61             0.0909          
  ======================================================================


====================================================================================================
6. SENSITIVITY AND ROBUSTNESS ANALYSIS
====================================================================================================

6.1 Weight Perturbation Sensitivity
--------------------------------------------------

Monte Carlo simulation with 1,000 random weight perturbations tests ranking
stability. High sensitivity indices indicate criteria whose weights strongly
influence final rankings.

  Overall Robustness Score: 0.9617
  Interpretation: Rankings are highly stable - minor weight changes have minimal impact

  Criteria Sensitivity Index (normalized 0-1):
  ------------------------------------------------------------
    C01: 1.0000 ██████████████████████████████ [HIGH]
    C05: 0.8220 ████████████████████████ [HIGH]
    C03: 0.7458 ██████████████████████ [HIGH]
    C02: 0.7373 ██████████████████████ [HIGH]
    C04: 0.5932 █████████████████ [MEDIUM]
    C17: 0.5932 █████████████████ [MEDIUM]
    C19: 0.5763 █████████████████ [MEDIUM]
    C14: 0.5678 █████████████████ [MEDIUM]
    C09: 0.5508 ████████████████ [MEDIUM]
    C18: 0.5508 ████████████████ [MEDIUM]
  ------------------------------------------------------------

  POLICY IMPLICATION:
  Criteria C01, C05, C03 have high sensitivity. Policy interventions
  targeting these areas will have the greatest impact on rankings.


====================================================================================================
7. FORECASTING RESULTS FOR 2025
====================================================================================================

7.1 Methodology
--------------------------------------------------

An ensemble of machine learning models was trained on 14 years of historical
data (2011-2024) to forecast criteria values for 2025.
The ensemble combines Gradient Boosting, Bayesian Ridge, and Huber regression
with automatic performance-based weighting.

  Model Contributions to Ensemble:
    BayesianRidge       : 0.9978 ███████████████████████████████████████
    GradientBoosting    : 0.0022 
    RandomForest        : 0.0000 
    Huber               : 0.0000 

7.2 Predicted Rankings for 2025
--------------------------------------------------

  Predicted TOPSIS Score Distribution:
    Best Predicted Score: 0.858526
    Worst Predicted Score: 0.176684
    Mean Predicted Score: 0.489534
    Score Change from 2024: -0.001827

  Predicted Top 15 Rankings for 2025:
  ======================================================================
  Rank   Entity          Predicted Score    Change from 2024 
  ======================================================================
  1      P14             0.858526           →
  2      P13             0.818822           →
  3      P06             0.816682           →
  4      P05             0.809057           ↑3
  5      P03             0.799115           →
  6      P08             0.798860           ↑2
  7      P10             0.796873           ↑2
  8      P04             0.795251           ↓4
  9      P01             0.791099           ↓3
  10     P07             0.782056           →
  11     P15             0.774082           →
  12     P12             0.757193           →
  13     P09             0.751762           →
  14     P11             0.751111           ↑1
  15     P02             0.741157           ↓1
  ======================================================================

7.3 Predicted VIKOR Analysis for 2025
--------------------------------------------------

  Predicted Q Value Range: [0.000000, 1.000000]

  Predicted VIKOR Top 5:
    1. P14: Q = 0.000000
    2. P06: Q = 0.096548
    3. P05: Q = 0.108445
    4. P01: Q = 0.137881
    5. P08: Q = 0.141141


====================================================================================================
8. CONCLUSIONS AND RECOMMENDATIONS
====================================================================================================

8.1 Summary of Key Findings
--------------------------------------------------

  1. PERFORMANCE LEADERS (2024):
     • P14 (Rank 1): Demonstrates excellence across
       multiple sustainability dimensions with Borda score 62.45
     • P13 (Rank 2): Demonstrates excellence across
       multiple sustainability dimensions with Borda score 61.18
     • P06 (Rank 3): Demonstrates excellence across
       multiple sustainability dimensions with Borda score 61.18

  2. AREAS FOR IMPROVEMENT:
     • P61 (Rank 64): Requires targeted
       interventions to improve sustainability performance
     • P52 (Rank 63): Requires targeted
       interventions to improve sustainability performance
     • P49 (Rank 62): Requires targeted
       interventions to improve sustainability performance

  3. METHODOLOGICAL ROBUSTNESS:
     • Excellent inter-method agreement (Kendall's W = 0.9681)
     • ML model explains 84.6% of performance variance
     • Rankings show 96.2% robustness to weight perturbations

  4. FORECAST (2025):
     • Mean predicted score: 0.4895
     • Overall trend: Slight decline expected

8.2 Policy Recommendations
--------------------------------------------------

  1. PRIORITY FOCUS AREAS: C21, C23, C26
     These criteria have the highest influence on sustainability rankings.
     Policy interventions should prioritize improvements in these areas.

  2. SENSITIVE INDICATORS: C01, C05, C03
     Rankings are most sensitive to these criteria weights.
     Ensure accurate measurement and appropriate weighting for these factors.


8.3 Limitations and Future Research
--------------------------------------------------

  • Data limited to 14 years; longer time series would improve forecasting accuracy
  • Equal treatment of all criteria types (benefit/cost) may oversimplify
  • External factors (policy changes, economic shocks) not explicitly modeled
  • Future research should incorporate spatial spillover effects


====================================================================================================
APPENDIX: TECHNICAL SPECIFICATIONS
====================================================================================================

A.1 Computational Environment
--------------------------------------------------
  Total Execution Time: 721.03 seconds
  Report Generated: 2026-02-11 01:20:04

A.2 MCDM Method Parameters
--------------------------------------------------
  TOPSIS: Vector normalization, ensemble weights
  Dynamic TOPSIS: Temporal discount=0.9, trajectory weight=0.3, stability weight=0.2
  VIKOR: v parameter=0.5 (group utility vs individual regret trade-off)
  Fuzzy: Triangular fuzzy numbers with temporal variance modeling

A.3 Machine Learning Configuration
--------------------------------------------------
  Random Forest: 200 estimators, max_depth=10, time-series CV (2 splits)
  Ensemble Forecasting: Gradient Boosting + Bayesian Ridge + Huber
  Cross-validation: Time-series aware splitting (no data leakage)

====================================================================================================
END OF REPORT
====================================================================================================