# ML-MCDM Framework

**A Hybrid Multi-Criteria Decision Making Framework with Intuitionistic Fuzzy Sets, Evidential Reasoning, and Ensemble Machine Learning**

[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/status-production-brightgreen.svg)](https://github.com/hoangsonww/ml-mcdm)

## Overview

This framework combines state-of-the-art Multi-Criteria Decision Making (MCDM) methods with Machine Learning to analyze and forecast multi-dimensional performance across entities. It integrates three major components:

1. **Objective Weighting** via Game Theory Weight Combination (GTWC)
2. **Hierarchical Ranking** using Intuitionistic Fuzzy Sets (IFS) + Evidential Reasoning (ER)
3. **ML Feature Importance** via Random Forest with cross-validation

**Application:** Vietnam PAPI (Provincial Governance and Public Administration Performance Index) analysis across 63 provinces over 14 years (2011-2024).

---

## Key Features

### ðŸŽ¯ Hierarchical Ranking System
- **12 MCDM Methods**: 6 Traditional + 6 IFS variants
  - Traditional: TOPSIS, VIKOR, PROMETHEE, COPRAS, EDAS, SAW
  - IFS Extensions: Handles uncertainty via Atanassov's Intuitionistic Fuzzy Sets
- **Two-Stage Architecture**: Within-criterion combination â†’ Global aggregation
- **Evidential Reasoning**: Rigorous belief combination (Yang & Xu, 2002)
- **Adaptive Zero-Handling**: Automatic exclusion of missing/zero data with restoration

### âš–ï¸ Objective Weight Calculation
- **4 Complementary Methods**: Entropy, CRITIC, MEREC, Standard Deviation
- **Game Theory Combination**: Intra-group hybridization + cooperative optimization
- **Uncertainty Quantification**: Bayesian Bootstrap (999 iterations)
- **Temporal Stability**: Split-half validation

### ðŸ¤– Machine Learning
- **Feature Importance**: Random Forest Gini importance with cross-validated RÂ²
- **Forecasting** *(available, currently isolated from pipeline)*:
  - 7 Model Types: GB, RF, ET, Bayesian Ridge, Huber, Ridge, MLP
  - Performance-Based Weighting, Uncertainty Quantification

### ðŸ“Š Analysis & Validation
- **Convergence Analysis**: Kendall's W concordance coefficient
- **Sensitivity Analysis**: Weight perturbation studies
- **Cross-Validation**: Time-series CV with proper temporal ordering
- **Robustness Testing**: Bootstrap confidence intervals

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Panel Data (N provinces Ã— T years Ã— p criteria)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WEIGHTING   â”‚   â”‚    RANKING      â”‚
â”‚              â”‚   â”‚                 â”‚
â”‚ â€¢ Entropy    â”‚   â”‚ Stage 1: Within â”‚
â”‚ â€¢ CRITIC     â”‚â”€â”€â–ºâ”‚  - Traditional  â”‚
â”‚ â€¢ MEREC      â”‚   â”‚  - IFS-MCDM     â”‚
â”‚ â€¢ Std Dev    â”‚   â”‚  - ER Combine   â”‚
â”‚              â”‚   â”‚                 â”‚
â”‚ Game Theory  â”‚   â”‚ Stage 2: Global â”‚
â”‚ Combination  â”‚   â”‚  - ER Aggregate â”‚
â”‚              â”‚   â”‚  - Final Rank   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â–¼            â–¼            â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ML FEATUREâ”‚ â”‚ ANALYSIS  â”‚ â”‚ VISUALISE â”‚
        â”‚ IMPORTANCEâ”‚ â”‚           â”‚ â”‚ & EXPORT  â”‚
        â”‚           â”‚ â”‚â€¢ Sensitiv.â”‚ â”‚           â”‚
        â”‚â€¢ RF Gini  â”‚ â”‚â€¢ Robust.  â”‚ â”‚â€¢ 5 charts â”‚
        â”‚â€¢ CV RÂ²    â”‚ â”‚â€¢ Kendall Wâ”‚ â”‚â€¢ 14 files â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Project Structure

```
ml-mcdm/
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ pyproject.toml          # Package configuration & dependencies
â”‚
â”œâ”€â”€ data/                   # Input data
â”‚   â”œâ”€â”€ 2011-2024.csv      # Historical panel data
â”‚   â””â”€â”€ codebook/          # Variable descriptions
â”‚
â”œâ”€â”€ pipeline.py            # Main orchestrator
â”œâ”€â”€ config.py              # Configuration management
â”œâ”€â”€ data_loader.py         # Data I/O and validation
â”œâ”€â”€ logger.py              # Logging system
â”œâ”€â”€ output_manager.py      # Results export
â”œâ”€â”€ visualization.py       # Chart generation (300 DPI)
â”‚
â”œâ”€â”€ weighting/             # Weight calculation
â”‚   â”œâ”€â”€ entropy.py
â”‚   â”œâ”€â”€ critic.py
â”‚   â”œâ”€â”€ merec.py
â”‚   â”œâ”€â”€ standard_deviation.py
â”‚   â”œâ”€â”€ fusion.py          # Game Theory Combination
â”‚   â””â”€â”€ hybrid_weighting.py  # Main interface
â”‚
â”œâ”€â”€ mcdm/                  # MCDM methods
â”‚   â”œâ”€â”€ traditional/       # Traditional MCDM
â”‚   â”‚   â”œâ”€â”€ topsis.py
â”‚   â”‚   â”œâ”€â”€ vikor.py
â”‚   â”‚   â”œâ”€â”€ promethee.py
â”‚   â”‚   â”œâ”€â”€ copras.py
â”‚   â”‚   â”œâ”€â”€ edas.py
â”‚   â”‚   â””â”€â”€ saw.py
â”‚   â””â”€â”€ ifs/               # Intuitionistic Fuzzy Sets
â”‚       â”œâ”€â”€ base.py
â”‚       â”œâ”€â”€ ifs_topsis.py
â”‚       â”œâ”€â”€ ifs_vikor.py
â”‚       â”œâ”€â”€ ifs_promethee.py
â”‚       â”œâ”€â”€ ifs_copras.py
â”‚       â”œâ”€â”€ ifs_edas.py
â”‚       â””â”€â”€ ifs_saw.py
â”‚
â”œâ”€â”€ evidential_reasoning/  # ER aggregation
â”‚   â”œâ”€â”€ base.py            # BeliefDistribution, ER engine
â”‚   â””â”€â”€ hierarchical_er.py # Two-stage hierarchical ER
â”‚
â”œâ”€â”€ ranking/               # Ranking orchestrator
â”‚   â””â”€â”€ pipeline.py        # Hierarchical ranking pipeline
â”‚
â”œâ”€â”€ analysis/              # Analysis tools
â”‚   â”œâ”€â”€ sensitivity.py
â”‚   â””â”€â”€ validation.py
â”‚
â”œâ”€â”€ forecasting/           # Machine learning (experimental)
â”‚   â”œâ”€â”€ base.py
â”‚   â”œâ”€â”€ features.py        # Feature engineering
â”‚   â”œâ”€â”€ tree_ensemble.py   # GB, RF, ET
â”‚   â”œâ”€â”€ linear.py          # Bayesian, Huber, Ridge
â”‚   â”œâ”€â”€ neural.py          # MLP, Attention
â”‚   â””â”€â”€ unified.py         # Ensemble orchestrator
â”‚
â”œâ”€â”€ tests/                 # Test suite
â”‚   â””â”€â”€ weighting/         # Weighting module tests
â”‚
â”œâ”€â”€ outputs/               # Generated results (git-ignored)
â”‚   â”œâ”€â”€ figures/          # PNG charts (300 DPI)
â”‚   â”œâ”€â”€ results/          # CSV files
â”‚   â”œâ”€â”€ reports/          # Text reports
â”‚   â””â”€â”€ logs/             # Debug logs
â”‚
â””â”€â”€ docs/                  # Documentation
    â”œâ”€â”€ objective.md       # Project objectives
    â”œâ”€â”€ dataset_description.md  # Data description
    â”œâ”€â”€ workflow.md        # Pipeline workflow
    â”œâ”€â”€ weighting.md       # Weight calculation details
    â”œâ”€â”€ ranking.md         # IFS+ER ranking methodology
    â””â”€â”€ forecast.md        # ML forecasting methods
```

---

## Documentation

### Core Documentation

| Document | Description |
|----------|-------------|
| [objective.md](docs/objective.md) | Project objectives and research questions |
| [dataset_description.md](docs/dataset_description.md) | Data structure and variables |
| [workflow.md](docs/workflow.md) | Pipeline workflow and execution |

### Technical Documentation

| Document | Description |
|----------|-------------|
| [weighting.md](docs/weighting.md) | Game Theory Weight Combination (GTWC) methodology |
| [ranking.md](docs/ranking.md) | IFS-MCDM + Evidential Reasoning details |
| [forecast.md](docs/forecast.md) | Ensemble ML forecasting architecture |

---

## Methodology Highlights

### Intuitionistic Fuzzy Sets (IFS)

Extends classical fuzzy sets by introducing independent non-membership:

$$
\text{IFN} = (\mu, \nu, \pi)
$$

Where:
- **Î¼ (mu)**: Membership degree âˆˆ [0, 1]
- **Î½ (nu)**: Non-membership degree âˆˆ [0, 1]
- **Ï€ (pi)**: Hesitancy = 1 - Î¼ - Î½
- **Constraint**: Î¼ + Î½ â‰¤ 1

**Construction from temporal data:**
- Î¼: Normalized current value
- Î½: Temporal variance (historical std)
- Ï€: Unexplained uncertainty

**Reference:** Atanassov, K.T. (1986). Intuitionistic fuzzy sets. *Fuzzy Sets and Systems*, 20(1), 87-96.

---

### Evidential Reasoning (ER)

Combines multiple assessments into belief distributions over evaluation grades:

$$
\text{Belief} = \{(\text{Excellent}, \beta_E), (\text{Good}, \beta_G), (\text{Fair}, \beta_F), (\text{Poor}, \beta_P), (\text{Bad}, \beta_B), (H, \beta_H)\}
$$

**Pairwise combination:**
$$
\beta_n = K \left[\beta_{1,n}\beta_{2,n} + \beta_{1,n}\beta_{2,H} + \beta_{1,H}\beta_{2,n}\right]
$$

Where K is normalization constant handling conflicts.

**Two-stage architecture:**
1. **Stage 1**: Within each criterion, combine 12 method scores via ER
2. **Stage 2**: Combine 8 criterion beliefs via weighted ER

**Reference:** Yang, J.B., & Xu, D.L. (2002). On the evidential reasoning algorithm. *IEEE Trans. SMC-A*, 32(3), 289-304.

---

### Game Theory Weight Combination (GTWC)

Combines 4 weighting methods through:

1. **Intra-Group Hybridization:**
   - Group A (Dispersion): Geometric mean of Entropy + Std Dev
   - Group B (Interaction): Harmonic mean of CRITIC + MEREC

2. **Cooperative Game Optimization:**
   $$
   \min L = \|Î±_1W_A + Î±_2W_B - W_A\|^2 + \|Î±_1W_A + Î±_2W_B - W_B\|^2
   $$

3. **Final Aggregation:**
   $$
   W^* = Î±_1 \cdot W_{\text{GroupA}} + Î±_2 \cdot W_{\text{GroupB}}
   $$

4. **Bayesian Bootstrap:** 999 iterations for uncertainty quantification

---

### ML Feature Importance

Random Forest Gini importance quantifies each feature's contribution to
ranking prediction.  Cross-validated RÂ² provides reliability.

> *Full ensemble forecasting (7 models) is implemented in the `forecasting/`
> module but is currently experimental and isolated from the main pipeline.
> It will be enhanced and integrated in future releases.*

---

## Output Files

### Results (CSV)

| File | Description |
|------|-------------|
| `final_rankings.csv` | Final province rankings with ER scores |
| `criterion_weights.csv` | GTWC weights with bootstrap uncertainty |
| `mcdm_scores_C01â€“C08.csv` | Per-criterion scores from 12 methods |
| `mcdm_rank_comparison.csv` | Rank comparison across MCDM methods |
| `weights_analysis.csv` | Weight derivation details |
| `feature_importance.csv` | RF Gini importance scores |
| `cv_scores.csv` | Cross-validation RÂ² by fold |
| `sensitivity_analysis.csv` | Weight perturbation results |
| `robustness_summary.csv` | Robustness metrics |
| `prediction_uncertainty_er.csv` | ER belief-structure uncertainty |
| `data_summary_statistics.csv` | Descriptive statistics of input data |
| `execution_summary.json` | Pipeline timing and metadata |
| `config_snapshot.json` | Full configuration used |

### Figures (PNG, 300 DPI)

- Final ranking summary chart
- Score distribution across provinces
- Weight comparison across criteria
- Sensitivity analysis heatmap
- Feature importance bar chart

### Reports (TXT)

- `report.txt`: Comprehensive analysis summary
- `debug.log`: Detailed execution log

---

## License

MIT License - see [LICENSE](LICENSE) for details.

---

## References

### Core Methodologies

1. **Atanassov, K.T.** (1986). Intuitionistic fuzzy sets. *Fuzzy Sets and Systems*, 20(1), 87-96.

2. **Yang, J.B., & Xu, D.L.** (2002). On the evidential reasoning algorithm for multiple attribute decision analysis under uncertainty. *IEEE Transactions on Systems, Man, and Cyberneticsâ€”Part A*, 32(3), 289-304.

3. **Hwang, C.L., & Yoon, K.** (1981). *Multiple Attribute Decision Making: Methods and Applications*. Springer.

4. **Keshavarz-Ghorabaee, M., et al.** (2021). Determination of Objective Weights Using a New Method Based on the Removal Effects of Criteria (MEREC). *Symmetry*, 13(4), 525.

5. **Diakoulaki, D., Mavrotas, G., & Papayannakis, L.** (1995). Determining objective weights in multiple criteria problems: The CRITIC method. *Computers & Operations Research*, 22(7), 763-770.

6. **Friedman, J.H.** (2001). Greedy function approximation: A gradient boosting machine. *Annals of Statistics*, 29(5), 1189-1232.

7. **Breiman, L.** (2001). Random forests. *Machine Learning*, 45(1), 5-32.